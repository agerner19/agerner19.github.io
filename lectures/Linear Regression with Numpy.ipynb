{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why NumPy\n",
    "In the previous class we walked through a bunch of the functionality provided in the NumPy package, but functionality doesn't touch on why or how this package is so useful.\n",
    "\n",
    "In this notebook we will walkthrough some more real world examples on why NumPy is a powerful assest when analyzing datasets in the real world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([1,2,3,np.nan])\n",
    "print(np.nanmean(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "Linear Regression is commonly structured as follows:\n",
    "\n",
    "$$ y = B_01 + B_1x_1 + B_2x_2 + ... + B_nx_n$$\n",
    "\n",
    "Where $B_n$ represents some weight we are applying to some input $x_n$. Another way to phrase this equation is taking the **weighted sum** of our **inputs** to produce a **prediction**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up our Linear Regression Problem\n",
    "First we need to initialize some data. In our case, we'll use the randomly generated data from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rand\n",
    "\n",
    "male_height = rand.normal(loc=70, scale=4, size=1000)\n",
    "male_weight = rand.normal(loc=170, scale=40, size=1000)\n",
    "male_age = 3/4 * (male_weight - male_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack([male_height, male_weight]).T\n",
    "y = male_age.reshape(X.shape[0],1)\n",
    "print(X[:5])\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "    \n",
    "fig= plt.figure()\n",
    "axes=fig.add_subplot(111, projection='3d')\n",
    "axes.scatter(X[:,0], X[:,1], y[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating our inputs for an intercept and adding our weights\n",
    "We'll actually want to add a placeholder **1** for our inputs for the intercept term. In addition we will want to randomly initialize some weights to go along with our inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = np.ones(shape=X.shape[0])\n",
    "int_X = np.vstack([intercept.T, X.T]).T\n",
    "print(int_X[:5])\n",
    "\n",
    "weights = rand.normal(size=(3,1))\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our baseline predictions\n",
    "By **weighting** our **inputs** we can get our preliminary **predictions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = int_X.dot(weights)\n",
    "print(f'Predictions:\\n{predictions[:10]}\\n')\n",
    "print(f'Actual:\\n{y[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving our preliminary predictions\n",
    "We'll need some helper functions to help improve these results form their initial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(pred, y):\n",
    "    \"\"\"Calculates the loss or error in our predictions - MSE\n",
    "    Args:\n",
    "        pred (np.array(floats)) - predictions for this iteration\n",
    "        y (np.array(floats)) - actual\n",
    "    Returns:\n",
    "        float - error\"\"\"\n",
    "    return(np.sum(np.power((y-pred), 2))/y.shape[0])\n",
    "\n",
    "def predict(X, W):\n",
    "    \"\"\"Make a predition based on our inputs and weights\n",
    "    Args:\n",
    "        X (np.array(floats)) - our inputs\n",
    "        W (np.array(floats)) - our weights\n",
    "    Returns:\n",
    "        np.array(floats) - predictions\"\"\"\n",
    "    \n",
    "    return(X.dot(W))\n",
    "\n",
    "def update_weights_linear(X, W, pred, y, lr):\n",
    "    \"\"\"Update our weights based on our loss and use of SGD\n",
    "    Args:\n",
    "        X -\n",
    "        W - \n",
    "        pred - \n",
    "        y - \n",
    "        lr (float) - learning rate for our gradient descent\n",
    "    Returns:\n",
    "        np.array(float) - updated weights from that cycle\"\"\"\n",
    "    w_gradient = -X.T.dot((y-pred))\n",
    "    w_gradient /= X.shape[0]\n",
    "    # This calculates the gradient on a per feature basis\n",
    "    W = W - (lr * w_gradient).reshape(X.shape[1], 1)\n",
    "    return(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD\n",
    "For those of you not as familiar with how we train a linear regression model this is a quick recap of SGD or Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "grad = lambda x: 2*x # The derivative, thus gradient, of x^2 is 2x\n",
    "lr = .05\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "def animate_sgd(i):\n",
    "    ax1.clear()\n",
    "    ax1.plot(x,y)\n",
    "    ax1.plot(curr_pos[i], curr_pos[i]**2, 'r+')\n",
    "\n",
    "x = np.arange(-50, 50)\n",
    "y = np.power(x, 2)\n",
    "curr_pos = []\n",
    "\n",
    "curr_x = -50\n",
    "for _ in range(50):\n",
    "    curr_x -= grad(curr_x) * lr\n",
    "    curr_pos.append(curr_x)\n",
    "\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate_sgd, frames=range(1, len(curr_pos)), interval=200, repeat=True)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting this all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = weights\n",
    "its = 2000\n",
    "for ix in range(its):\n",
    "    preds = predict(int_X, W)\n",
    "    mse = loss(preds, y)\n",
    "    if ix % int(its/10) == 0:\n",
    "        print(f'MSE: {mse}')\n",
    "    W = update_weights_linear(int_X, W, preds, y, 0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(int_X, W)\n",
    "print(f'Predictions:\\n{preds[:5]}\\n')\n",
    "print(f'Actual:\\n{y[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-prog_analytics] *",
   "language": "python",
   "name": "conda-env-.conda-prog_analytics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
